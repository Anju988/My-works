{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKT4_Std2LQa"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from IPython import display\n",
        "display.set_matplotlib_formats(\"svg\")\n",
        "\n",
        "iris = pd.read_csv(\"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\")\n",
        "iris.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(iris.drop(\"variety\", axis=1).values, dtype=torch.float)\n",
        "y = torch.tensor(\n",
        "    [0 if vty == \"Setosa\" else 1 if vty == \"Versicolor\" else 2 for vty in iris[\"variety\"]],\n",
        "    dtype=torch.long\n",
        ")\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "mRiA4YBW2pjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
        "\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=12)\n",
        "test_loader = DataLoader(test_data, batch_size=len(test_data.tensors[0]))\n",
        "\n",
        "print(\"Training data batches:\")\n",
        "for X, y in train_loader:\n",
        "    print(X.shape, y.shape)\n",
        "\n",
        "print(\"\\nTest data batches:\")\n",
        "for X, y in test_loader:\n",
        "    print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "bjfSuKQ424ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input = nn.Linear(in_features=4, out_features=16)\n",
        "        self.hidden_1 = nn.Linear(in_features=16, out_features=16)\n",
        "        self.output = nn.Linear(in_features=16, out_features=3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.input(x))\n",
        "        x = F.relu(self.hidden_1(x))\n",
        "        return self.output(x)\n",
        "\n",
        "\n",
        "model = Net()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "c0tQIACd28zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 200\n",
        "train_accuracies, test_accuracies = [], []\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train set\n",
        "    for X, y in train_loader:\n",
        "        preds = model(X)\n",
        "        pred_labels = torch.argmax(preds, axis=1)\n",
        "        loss = loss_function(preds, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    train_accuracies.append(\n",
        "        100 * torch.mean((pred_labels == y).float()).item()\n",
        "    )\n",
        "\n",
        "    # Test set\n",
        "    X, y = next(iter(test_loader))\n",
        "    pred_labels = torch.argmax(model(X), axis=1)\n",
        "    test_accuracies.append(\n",
        "        100 * torch.mean((pred_labels == y).float()).item()\n",
        "    )"
      ],
      "metadata": {
        "id": "FV4eDF_O3JQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(tight_layout=True)\n",
        "gs = gridspec.GridSpec(nrows=2, ncols=1)\n",
        "\n",
        "ax = fig.add_subplot(gs[0, 0])\n",
        "ax.plot(train_accuracies)\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.set_ylabel(\"Training accuracy\")\n",
        "\n",
        "ax = fig.add_subplot(gs[1, 0])\n",
        "ax.plot(test_accuracies)\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.set_ylabel(\"Test accuracy\")\n",
        "\n",
        "fig.align_labels()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n0qnKr7A3e_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_loader, test_loader, model, lr=0.01, num_epochs=200):\n",
        "    train_accuracies, test_accuracies = [], []\n",
        "    losses = []\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for X, y in train_loader:\n",
        "            preds = model(X)\n",
        "            pred_labels = torch.argmax(preds, axis=1)\n",
        "            loss = loss_function(preds, y)\n",
        "            losses.append(loss.detach().numpy())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_accuracies.append(\n",
        "            100 * torch.mean((pred_labels == y).float()).item()\n",
        "        )\n",
        "\n",
        "        X, y = next(iter(test_loader))\n",
        "        pred_labels = torch.argmax(model(X), axis=1)\n",
        "        test_accuracies.append(\n",
        "            100 * torch.mean((pred_labels == y).float()).item()\n",
        "        )\n",
        "\n",
        "    return train_accuracies[-1], test_accuracies[-1]\n",
        "\n",
        "\n",
        "train_model(train_loader, test_loader, Net())"
      ],
      "metadata": {
        "id": "5Mu9O5Bx3oNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self, n_units, n_layers):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers = nn.ModuleDict()\n",
        "        self.layers[\"input\"] = nn.Linear(in_features=4, out_features=n_units)\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            self.layers[f\"hidden_{i}\"] = nn.Linear(in_features=n_units, out_features=n_units)\n",
        "\n",
        "        self.layers[\"output\"] = nn.Linear(in_features=n_units, out_features=3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers[\"input\"](x)\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            x = F.relu(self.layers[f\"hidden_{i}\"](x))\n",
        "\n",
        "        return self.layers[\"output\"](x)"
      ],
      "metadata": {
        "id": "FDjfmySh9-bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = np.arange(1, 5)\n",
        "n_units = np.arange(8, 65, 8)\n",
        "train_accuracies, test_accuracies = [], []\n",
        "\n",
        "for i in range(len(n_units)):\n",
        "    for j in range(len(n_layers)):\n",
        "        model = Net2(n_units=n_units[i], n_layers=n_layers[j])\n",
        "        train_acc, test_acc = train_model(train_loader, test_loader, model)\n",
        "        train_accuracies.append({\n",
        "            \"n_layers\": n_layers[j],\n",
        "            \"n_units\": n_units[i],\n",
        "            \"accuracy\": train_acc\n",
        "        })\n",
        "        test_accuracies.append({\n",
        "            \"n_layers\": n_layers[j],\n",
        "            \"n_units\": n_units[i],\n",
        "            \"accuracy\": test_acc\n",
        "        })\n",
        "\n",
        "\n",
        "train_accuracies = pd.DataFrame(train_accuracies).sort_values(by=[\"n_layers\", \"n_units\"]).reset_index(drop=True)\n",
        "test_accuracies = pd.DataFrame(test_accuracies).sort_values(by=[\"n_layers\", \"n_units\"]).reset_index(drop=True)\n",
        "test_accuracies.head()"
      ],
      "metadata": {
        "id": "PCstdfY3-LyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracies[test_accuracies[\"accuracy\"] == test_accuracies[\"accuracy\"].max()]"
      ],
      "metadata": {
        "id": "ST1RpJZT_Acq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
